{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"import bz2, html, json, os, re, requests, subprocess\n\nfrom sqlitedict import SqliteDict\nfrom collections import defaultdict\nimport pandas as pd\n\nif not os.path.exists('python-utils'):\n    subprocess.check_output('git clone https://github.com/CMU-CREATE-Lab/python-utils.git', shell=True)\n\ndef exec_ipynb(filename_or_url):\n    nb = (requests.get(filename_or_url).json() if re.match(r'https?:', filename_or_url) else json.load(open(filename_or_url)))\n    if(nb['nbformat'] >= 4):\n        src = [''.join(cell['source']) for cell in nb['cells'] if cell['cell_type'] == 'code']\n    else:\n        src = [''.join(cell['input']) for cell in nb['worksheets'][0]['cells'] if cell['cell_type'] == 'code']\n    exec('\\n'.join(src), globals())\n\nos.chdir('/t/esdr-connectors/mirror-purpleair-to-esdr/') \nexec_ipynb('python-utils/utils.ipynb')\nexec_ipynb('python-utils/esdr-library.ipynb')\nnotebook_wide_display()"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"Stat.set_service('Purpleair upload to ESDR realtime')\nprogress = SqliteDict('upload-purpleair-realtime.sqlite', autocommit=True)"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":"# First time uploading, create a new client like so:\n\n# Esdr.save_client('esdr-auth-purpleair-uploader.json', 'PurpleAir uploader for timemachine1')\n\n# and then follow the directions it prints, which include visiting esdr.cmucreatelab.org and creating\n# a client with given parameters, and also editing esdr-auth-baaqm-uploader.json to include your\n# username and password\n\n# Do not add esdr-auth-*.json to the git repo\n# !echo 'esdr-auth-*.json' >>.gitignore\n\nesdr = Esdr('esdr-auth-purpleair-uploader.json')"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"############################################\n#\n# Parse and convert device records to ESDR\n#\n\ndef computeLatLon(deviceRecord):\n    return (float(deviceRecord['Lat']), float(deviceRecord['Lon']))\n\ndef computeEsdrId(deviceRecord):\n    lat, lon = computeLatLon(deviceRecord)\n\n    id = \"%s_%06d%s%06d%s\" % (deviceRecord['ID'], \n                              round(1000 * abs(lat)), 'NS'[lat < 0], \n                              round(1000 * abs(lon)), 'EW'[lon < 0])\n    return id.replace('.','_')\n\ndef computeEpochTimestamp(deviceRecord):\n    try:\n        return json.loads(deviceRecord['Stats'])['lastModified'] / 1000.0\n    except:\n        return None\n    \ndef computeEsdrRecord(deviceRecord):\n    data = {}\n    \n    data['time'] = computeEpochTimestamp(deviceRecord)\n\n    for key in ['PM2_5Value', 'RSSI', 'Uptime', 'humidity', 'pressure', 'temp_f']:\n        translated_key = key\n        if key == 'PM2_5Value':\n            translated_key = 'PM2_5'\n        try:\n            data[translated_key] = float(deviceRecord[key])\n        except:\n            pass\n\n    try:\n        stats = json.loads(deviceRecord['Stats'])\n        for key in stats.keys():\n            if key == 'lastModified' or key == 'timeSinceModified':\n                continue\n            data['stats_' + key] = stats[key]\n    except:\n        # Stats stopped being reported Jan 2018\n        pass\n\n    return data\n    \ndef computeEsdrName(deviceRecord):\n    return deviceRecord['Label'].strip()\n\n\n###########################################################\n#\n# Accumulate deviceRecords from multiple JSON input files\n#\n\ndef accumulateReset():\n    global accumulator\n    accumulator = defaultdict(lambda: {'records':defaultdict(lambda: {})})\n\ndef accumulateJson(path):\n    nUploads = 0\n    locationCounts = defaultdict(lambda:0)\n    js = json.load(bz2.open(path, 'r'))\n    records = js['results']\n    for deviceRecord in records:\n        if not ('Lat' in deviceRecord) or not ('Lon' in deviceRecord):\n            locationCounts['noLatLon'] += 1\n            continue\n            \n        epochTimestamp = computeEpochTimestamp(deviceRecord)\n        if not epochTimestamp:\n            locationCounts['noTimestamp'] += 1\n            continue\n\n        location = deviceRecord.get('DEVICE_LOCATIONTYPE','unspecified')\n        locationCounts[location] += 1\n        if location == 'inside':\n            continue\n        \n        esdrId = computeEsdrId(deviceRecord)\n        \n        a = accumulator[esdrId]\n        a['records'][epochTimestamp] = computeEsdrRecord(deviceRecord)\n        if 'name' in a:\n            assert a['name'] == computeEsdrName(deviceRecord)\n        a['name'] = computeEsdrName(deviceRecord)\n        lat, lon = computeLatLon(deviceRecord)\n        a['lat'] = lat\n        a['lon'] = lon\n        nUploads += 1\n\n    Stat.info('%s: using %d of %d records %s' % (path, nUploads, len(records), json.dumps(locationCounts)))\n    Stat.info('After merge, total of %d ESDR IDs' % len(accumulator))\n\n############################################\n#\n# Find JSON files we haven't processed yet\n#\n    \ndef pathTopDir(path):\n    return path.split('/')[0]\n\ndef pathSansTopDir(path):\n    tokens = path.split('/')\n    return '/'.join(tokens[1:])\n\n# Get newer files than path in dir\ndef getNewerFiles(dir, newerThan, nSubdirLevels):\n    ret = []\n    if nSubdirLevels:\n        for subdir in sorted(os.listdir(dir)):\n            if not newerThan or subdir > pathTopDir(newerThan):\n                for file in getNewerFiles(dir + '/' + subdir, None, nSubdirLevels-1):\n                    ret.append(subdir + '/' + file)\n            elif subdir == pathTopDir(newerThan):\n                for file in getNewerFiles(dir + '/' + subdir, pathSansTopDir(newerThan), nSubdirLevels-1):\n                    ret.append(subdir + '/' + file)\n    else:\n        for file in sorted(os.listdir(dir)):\n            if not newerThan or file > newerThan:\n                ret.append(file)\n    return ret\n\n###############################################\n#\n# Upload to ESDR\n#\n\ndef sortedDict(dict):\n    return {k:dict[k] for k in sorted(dict.keys()) }\n\ndef uploadId(id):\n    a = accumulator[id]\n    feed = esdr.cached_get_or_create_product_device_feed('PurpleAir', id, a['lat'], a['lon'])\n    dicts = list(sortedDict(a['records']).values())\n    df = pd.DataFrame(dicts)\n    esdr.upload_dicts(feed, dicts)\n    \n"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"while True:\n    lastUploaded = progress.get('lastUploaded', None)\n\n    files = getNewerFiles('mirror', lastUploaded, nSubdirLevels=1)\n    # Only json.bz2 files\n    files = list(filter(re.compile(r'\\.json\\.bz2$').search, files))\n\n    # A maximum of the first 100 files\n    files = files[0:100]\n\n    accumulateReset()\n\n    for file in files:\n        accumulateJson('mirror/' + file)\n\n    for id in sorted(accumulator.keys()):\n        uploadId(id)\n\n    Stat.up('Uploaded %d devices from %d files (%s ... %s)' % (len(accumulator), len(files), files[0], files[-1]))\n    progress['lastUploaded'] = files[-1]\n    \n\n"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}