{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import bz2, html, json, os, re, requests, subprocess, sys, dateutil, datetime, glob, stat\n",
    "\n",
    "from dateutil import rrule, tz, parser\n",
    "from sqlitedict import SqliteDict\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# if not os.path.exists('python-utils'):\n",
    "#     subprocess.check_output('git clone https://github.com/CMU-CREATE-Lab/python-utils.git', shell=True)\n",
    "\n",
    "# def exec_ipynb(filename_or_url):\n",
    "#     nb = (requests.get(filename_or_url).json() if re.match(r'https?:', filename_or_url) else json.load(open(filename_or_url)))\n",
    "#     if(nb['nbformat'] >= 4):\n",
    "#         src = [''.join(cell['source']) for cell in nb['cells'] if cell['cell_type'] == 'code']\n",
    "#     else:\n",
    "#         src = [''.join(cell['input']) for cell in nb['worksheets'][0]['cells'] if cell['cell_type'] == 'code']\n",
    "#     exec('\\n'.join(src), globals())\n",
    "\n",
    "# os.chdir('/t/esdr-connectors/mirror-purpleair-to-esdr/')\n",
    "# notebook_wide_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Boilerplate to load utils.ipynb\n",
    "# See https://github.com/CMU-CREATE-Lab/python-utils/blob/master/utils.ipynb\n",
    "\n",
    "\n",
    "def exec_ipynb(filename_or_url):\n",
    "    nb = (requests.get(filename_or_url).json() if re.match(r'https?:', filename_or_url) else json.load(open(filename_or_url)))\n",
    "    if(nb['nbformat'] >= 4):\n",
    "        src = [''.join(cell['source']) for cell in nb['cells'] if cell['cell_type'] == 'code']\n",
    "    else:\n",
    "        src = [''.join(cell['input']) for cell in nb['worksheets'][0]['cells'] if cell['cell_type'] == 'code']\n",
    "\n",
    "    tmpname = '/tmp/%s-%s-%d.py' % (os.path.basename(filename_or_url),\n",
    "                                    datetime.datetime.now().strftime('%Y%m%d%H%M%S%f'),\n",
    "                                    os.getpid())\n",
    "    src = '\\n\\n\\n'.join(src)\n",
    "    open(tmpname, 'w').write(src)\n",
    "    code = compile(src, tmpname, 'exec')\n",
    "    exec(code, globals())\n",
    "\n",
    "\n",
    "exec_ipynb('./python-utils/utils.ipynb')\n",
    "exec_ipynb('./python-utils/esdr-library.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "STAT_SERVICE_NAME = 'Purpleair upload to ESDR realtime'\n",
    "STAT_HOSTNAME = 'hal21'\n",
    "STAT_SHORTNAME = 'airnow-highest-five-uploader'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "Stat.set_service(STAT_SERVICE_NAME)\n",
    "progress = SqliteDict('upload-purpleair-realtime.sqlite', autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# First time uploading, create a new client like so:\n",
    "\n",
    "# Esdr.save_client('esdr-auth-purpleair-uploader.json', 'PurpleAir uploader for timemachine1')\n",
    "\n",
    "# and then follow the directions it prints, which include visiting esdr.cmucreatelab.org and creating\n",
    "# a client with given parameters, and also editing esdr-auth-baaqm-uploader.json to include your\n",
    "# username and password\n",
    "\n",
    "# Do not add esdr-auth-*.json to the git repo\n",
    "# !echo 'esdr-auth-*.json' >>.gitignore\n",
    "\n",
    "esdr = Esdr('esdr-auth-purpleair-uploader.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "############################################\n",
    "#\n",
    "# Parse and convert device records to ESDR\n",
    "#\n",
    "\n",
    "def computeLatLon(deviceRecord):\n",
    "    return (float(deviceRecord['Lat']), float(deviceRecord['Lon']))\n",
    "\n",
    "def computeEsdrId(deviceRecord):\n",
    "    lat, lon = computeLatLon(deviceRecord)\n",
    "\n",
    "    id = \"%s_%06d%s%06d%s\" % (deviceRecord['ID'], \n",
    "                              round(1000 * abs(lat)), 'NS'[lat < 0], \n",
    "                              round(1000 * abs(lon)), 'EW'[lon < 0])\n",
    "    return id.replace('.','_')\n",
    "\n",
    "def computeEpochTimestamp(deviceRecord):\n",
    "    try:\n",
    "        return json.loads(deviceRecord['Stats'])['lastModified'] / 1000.0\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def computeEsdrRecord(deviceRecord):\n",
    "    data = {}\n",
    "    \n",
    "    data['time'] = computeEpochTimestamp(deviceRecord)\n",
    "\n",
    "    for key in ['PM2_5Value', 'RSSI', 'Uptime', 'humidity', 'pressure', 'temp_f']:\n",
    "        translated_key = key\n",
    "        if key == 'PM2_5Value':\n",
    "            translated_key = 'PM2_5'\n",
    "        try:\n",
    "            data[translated_key] = float(deviceRecord[key])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    try:\n",
    "        stats = json.loads(deviceRecord['Stats'])\n",
    "        for key in stats.keys():\n",
    "            if key == 'lastModified' or key == 'timeSinceModified':\n",
    "                continue\n",
    "            data['stats_' + key] = stats[key]\n",
    "    except:\n",
    "        # Stats stopped being reported Jan 2018\n",
    "        pass\n",
    "\n",
    "    return data\n",
    "    \n",
    "def computeEsdrName(deviceRecord):\n",
    "    if 'Label' in deviceRecord:\n",
    "        return deviceRecord['Label'].strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "###########################################################\n",
    "#\n",
    "# Accumulate deviceRecords from multiple JSON input files\n",
    "#\n",
    "\n",
    "def accumulateReset():\n",
    "    global accumulator\n",
    "    accumulator = defaultdict(lambda: {'records':defaultdict(lambda: {})})\n",
    "\n",
    "def accumulateJson(path):\n",
    "    nUploads = 0\n",
    "    nonameCount = 0\n",
    "    locationCounts = defaultdict(lambda:0)\n",
    "    js = json.load(bz2.open(path, 'r'))\n",
    "    records = js['results']\n",
    "    for deviceRecord in records:\n",
    "        if not ('Lat' in deviceRecord) or not ('Lon' in deviceRecord):\n",
    "            locationCounts['noLatLon'] += 1\n",
    "            continue\n",
    "            \n",
    "        epochTimestamp = computeEpochTimestamp(deviceRecord)\n",
    "        if not epochTimestamp:\n",
    "            locationCounts['noTimestamp'] += 1\n",
    "            continue\n",
    "\n",
    "        location = deviceRecord.get('DEVICE_LOCATIONTYPE','unspecified')\n",
    "        locationCounts[location] += 1\n",
    "        if location == 'inside':\n",
    "            continue\n",
    "        \n",
    "        esdrId = computeEsdrId(deviceRecord)\n",
    "        \n",
    "        a = accumulator[esdrId]\n",
    "        record = computeEsdrRecord(deviceRecord)\n",
    "        name = computeEsdrName(deviceRecord)\n",
    "        if not name:\n",
    "            nonameCount += 1\n",
    "            continue\n",
    "        #if 'name' in a and a['name'] != name:\n",
    "        #    raise Exception('Trying to add %s to %s, but name %s is different from %s' %\n",
    "        #                    (record, a, name, a['name']))\n",
    "        a['records'][epochTimestamp] = record\n",
    "        a['name'] = name\n",
    "        lat, lon = computeLatLon(deviceRecord)\n",
    "        a['lat'] = lat\n",
    "        a['lon'] = lon\n",
    "        nUploads += 1\n",
    "\n",
    "    Stat.info('%s: using %d of %d records %s' % (path, nUploads, len(records), json.dumps(locationCounts)), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    Stat.info('After merge, total of %d ESDR IDs' % len(accumulator), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    if nonameCount:\n",
    "        Stat.warning('%d purpleair records had no Label field and could not be merged' % nonameCount, host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "\n",
    "############################################\n",
    "#\n",
    "# Find JSON files we haven't processed yet\n",
    "#\n",
    "    \n",
    "def pathTopDir(path):\n",
    "    return path.split('/')[0]\n",
    "\n",
    "def pathSansTopDir(path):\n",
    "    tokens = path.split('/')\n",
    "    return '/'.join(tokens[1:])\n",
    "\n",
    "# Get newer files than path in dir\n",
    "def getNewerFiles(dir, newerThan, nSubdirLevels):\n",
    "    ret = []\n",
    "    if nSubdirLevels:\n",
    "        for subdir in sorted(os.listdir(dir)):\n",
    "            if not newerThan or subdir > pathTopDir(newerThan):\n",
    "                for file in getNewerFiles(dir + '/' + subdir, None, nSubdirLevels-1):\n",
    "                    ret.append(subdir + '/' + file)\n",
    "            elif subdir == pathTopDir(newerThan):\n",
    "                for file in getNewerFiles(dir + '/' + subdir, pathSansTopDir(newerThan), nSubdirLevels-1):\n",
    "                    ret.append(subdir + '/' + file)\n",
    "    else:\n",
    "        for file in sorted(os.listdir(dir)):\n",
    "            if not newerThan or file > newerThan:\n",
    "                ret.append(file)\n",
    "    return ret\n",
    "\n",
    "###############################################\n",
    "#\n",
    "# Upload to ESDR\n",
    "#\n",
    "\n",
    "def sortedDict(dict):\n",
    "    return {k:dict[k] for k in sorted(dict.keys()) }\n",
    "\n",
    "def uploadId(id):\n",
    "    a = accumulator[id]\n",
    "    feed = esdr.cached_get_or_create_product_device_feed('PurpleAir', id, a['lat'], a['lon'])\n",
    "    dicts = list(sortedDict(a['records']).values())\n",
    "    df = pd.DataFrame(dicts)\n",
    "    esdr.upload_dicts(feed, dicts)\n",
    "    sys.stdout.flush()\n",
    "    sys.stderr.flush()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "while True:\n",
    "    lastUploaded = progress.get('lastUploaded', None)\n",
    "\n",
    "    files = getNewerFiles('mirror', lastUploaded, nSubdirLevels=1)\n",
    "    # Only json.bz2 files\n",
    "    files = list(filter(re.compile(r'\\.json\\.bz2$').search, files))\n",
    "\n",
    "    # A maximum of the first 100 files\n",
    "    files = files[0:100]\n",
    "\n",
    "    accumulateReset()\n",
    "\n",
    "    for file in files:\n",
    "        accumulateJson('mirror/' + file)\n",
    "\n",
    "    for id in sorted(accumulator.keys()):\n",
    "        uploadId(id)\n",
    "\n",
    "    Stat.up('Uploaded %d devices from %d files (%s ... %s)' % (len(accumulator), len(files), files[0], files[-1]), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME,\n",
    "            valid_for_secs=3600 * 2)\n",
    "    progress['lastUploaded'] = files[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Anaconda Python 3",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 0
}