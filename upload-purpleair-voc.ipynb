{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload PurpleAir VOC\n",
    "\n",
    "Processes PurpleAir VOC data files, aggregating by monitor, and uploads to ESDR.  Runs every 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json, datetime, html, subprocess, sys, dateutil, datetime, glob, stat, time\n",
    "\n",
    "from dateutil import rrule, tz, parser\n",
    "from sqlitedict import SqliteDict\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate to load utils.ipynb\n",
    "# See https://github.com/CMU-CREATE-Lab/python-utils/blob/master/utils.ipynb\n",
    "\n",
    "def exec_ipynb(filename_or_url):\n",
    "    nb = (requests.get(filename_or_url).json() if re.match(r'https?:', filename_or_url) else json.load(open(filename_or_url)))\n",
    "    if(nb['nbformat'] >= 4):\n",
    "        src = [''.join(cell['source']) for cell in nb['cells'] if cell['cell_type'] == 'code']\n",
    "    else:\n",
    "        src = [''.join(cell['input']) for cell in nb['worksheets'][0]['cells'] if cell['cell_type'] == 'code']\n",
    "\n",
    "    tmpname = '/tmp/%s-%s-%d.py' % (os.path.basename(filename_or_url),\n",
    "                                    datetime.datetime.now().strftime('%Y%m%d%H%M%S%f'),\n",
    "                                    os.getpid())\n",
    "    src = '\\n\\n\\n'.join(src)\n",
    "    open(tmpname, 'w').write(src)\n",
    "    code = compile(src, tmpname, 'exec')\n",
    "    exec(code, globals())\n",
    "\n",
    "exec_ipynb('./python-utils/utils.ipynb')\n",
    "exec_ipynb('./python-utils/esdr-library.ipynb')\n",
    "exec_ipynb('./purpleair-common.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT_SERVICE_NAME = 'PurpleAir Upload VOC'\n",
    "STAT_HOSTNAME = 'hal21'\n",
    "STAT_SHORTNAME = 'purpleair-upload-voc'\n",
    "\n",
    "Stat.set_service(STAT_SERVICE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs every 5 minutes\n",
    "RUN_INTERVAL_MINUTES = 5\n",
    "RUN_INTERVAL_SECONDS = 60 * RUN_INTERVAL_MINUTES\n",
    "\n",
    "# Maximum number of JSON data files to process per batch\n",
    "NUM_FILES_PER_BATCH = 500\n",
    "\n",
    "# let this script restart once per day, to deal with ESDR OAuth token refresh--see below\n",
    "NUM_ITERATIONS_BETWEEN_RESTARTS = int(60 * 24 / RUN_INTERVAL_MINUTES)\n",
    "\n",
    "SQLITE_PROGRESS_FILE = 'purpleair-upload-voc.sqlite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = SqliteDict(SQLITE_PROGRESS_FILE, autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esdr = Esdr('esdr-auth-purpleair-uploader.json', user_agent='esdr-library.py['+STAT_SERVICE_NAME+']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulator = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purpleair_product = None\n",
    "\n",
    "def get_purpleair_product():\n",
    "    try:\n",
    "        global esdr, purpleair_product\n",
    "        if not esdr:\n",
    "            esdr = Esdr('esdr-auth-airnow-uploader.json', user_agent='esdr-library.py['+STAT_SERVICE_NAME+']')\n",
    "        if not purpleair_product:\n",
    "            purpleair_product = esdr.get_product_by_name('PurpleAir')\n",
    "        return purpleair_product\n",
    "    except requests.HTTPError as e:\n",
    "        Stat.warning(f\"Failed to get PurpleAir ESDR product due to error: {str(e)}\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "        return None\n",
    "\n",
    "#get_purpleair_product()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_top_dir(path):\n",
    "    return path.split('/')[0]\n",
    "\n",
    "\n",
    "def path_sans_top_dir(path):\n",
    "    tokens = path.split('/')\n",
    "    return '/'.join(tokens[1:])\n",
    "\n",
    "\n",
    "# Get newer files than path in dir\n",
    "def get_newer_files(dir, newer_than, num_subdir_levels):\n",
    "    ret = []\n",
    "    if num_subdir_levels:\n",
    "        for subdir in sorted(os.listdir(dir)):\n",
    "            if not newer_than or subdir > path_top_dir(newer_than):\n",
    "                for file in get_newer_files(dir + '/' + subdir, None,\n",
    "                                            num_subdir_levels - 1):\n",
    "                    ret.append(subdir + '/' + file)\n",
    "            elif subdir == path_top_dir(newer_than):\n",
    "                for file in get_newer_files(dir + '/' + subdir,\n",
    "                                            path_sans_top_dir(newer_than),\n",
    "                                            num_subdir_levels - 1):\n",
    "                    ret.append(subdir + '/' + file)\n",
    "    else:\n",
    "        for file in sorted(os.listdir(dir)):\n",
    "            if not newer_than or file > newer_than:\n",
    "                ret.append(file)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lat_lon(record):\n",
    "    return (float(record['lat']), float(record['lon']))\n",
    "\n",
    "def compute_esdr_id(monitor_id, record):\n",
    "    lat, lon = compute_lat_lon(record)\n",
    "\n",
    "    id = \"%s_%06d%s%06d%s\" % (monitor_id,\n",
    "                              round(1000 * abs(lat)), 'NS'[lat < 0],\n",
    "                              round(1000 * abs(lon)), 'EW'[lon < 0])\n",
    "    return id.replace('.','_')\n",
    "\n",
    "#compute_esdr_id(50087, {\"lat\" : 40.10513, \"lon\" : -80.713005, \"voc\" : 92.44})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_reset():\n",
    "    global accumulator\n",
    "    accumulator = defaultdict(lambda: {'records':defaultdict(lambda: {})})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_json(path):\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "        timestamp = data['epoch_time']\n",
    "        monitors = data['monitors']\n",
    "        for monitor_id, monitor in monitors.items():\n",
    "            esdr_id = compute_esdr_id(monitor_id, monitor)\n",
    "            a = accumulator[esdr_id]\n",
    "            a['records'][timestamp] = {'time': timestamp, 'voc': float(monitor['voc'])}\n",
    "            lat, lon = compute_lat_lon(monitor)\n",
    "            a['lat'] = lat\n",
    "            a['lon'] = lon\n",
    "    Stat.info(f\"After merge of {path}, total of {len(accumulator)} ESDR IDs\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads metadata for the PurpleAir feed with the given serial number as the prefix of the feed name. For example,\n",
    "# calling load_esdr_feed_by_serial_number('94497_040689N080292W') will return {'id': 60360, 'name': '94497_040689N080292W PurpleAir'}\n",
    "def load_esdr_feed_by_serial_number(serial_number):\n",
    "    try:\n",
    "        # On the offchance there are multiple feeds with the same name, then we want the most recently\n",
    "        # created one, so we order by id in descending order. Note also that I get the name and device\n",
    "        # ID here because esdr.upload_dicts() uses it in it's print statement after uploading. Ugh.\n",
    "        response = esdr.query_first('/api/v1/feeds', {'whereAnd' : 'productId=%d,name=%s' % (purpleair_product['id'],serial_number + ' PurpleAir'), 'fields' : 'id,name,deviceId', 'limit': 1, 'orderBy' : '-id'})\n",
    "        return response\n",
    "    except requests.HTTPError as e:\n",
    "        Stat.warning(f\"Failed to upload to feed corresponding to ID {id} (HTTP {e.response.status_code})\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    except:\n",
    "        Stat.warning(f\"Failed to upload to feed corresponding to ID {id}\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "\n",
    "# get_purpleair_product()\n",
    "# print(load_esdr_feed_by_serial_number('119450_038680N121082W')) # {'id': 87520, 'name': '119450_038680N121082W PurpleAir'}\n",
    "# print(load_esdr_feed_by_serial_number('94497_040689N080292W')) # {'id': 60360, 'name': '94497_040689N080292W PurpleAir'}\n",
    "# print(load_esdr_feed_by_serial_number('bogus')) # None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_dict(dict):\n",
    "    return {k: dict[k] for k in sorted(dict.keys())}\n",
    "\n",
    "\n",
    "def upload(id):\n",
    "    try:\n",
    "        a = accumulator[id]\n",
    "        if 'lat' in a and 'lon' in a:\n",
    "            # Look up the feed by name, since it turns out that we can't rely on the lat/lon reporting by the API that this\n",
    "            # notebook uses as being the same lat/lon reported by the API that the main PurpleAir data mirror uses.  Which\n",
    "            # really kinda sucks and doesn't make a lot of sense.  Anyway, since the feed name is composed of the serial\n",
    "            # number (e.g. \"94497_040689N080292W\") plus the string \" PurpleAir\", then--for MOST cases--we should be able to\n",
    "            # simply query for a feed belonging to the PurpleAir product AND which has a name like \"94497_040689N080292W PurpleAir\"\n",
    "            feed = load_esdr_feed_by_serial_number(id)\n",
    "            if feed is None:\n",
    "                Stat.warning(f\"Skipping ID {id} because no matching ESDR feed could be found\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "            else:\n",
    "                dicts = list(sorted_dict(a['records']).values())\n",
    "\n",
    "                print(f\"Uploading to feed {feed['id']} which is {feed['name']}\")\n",
    "                esdr.upload_dicts(feed, dicts)\n",
    "                return True\n",
    "        else:\n",
    "            Stat.warning(f\"Skipping upload for ID {id} because it has no lat/lon\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    except requests.HTTPError as e:\n",
    "        Stat.warning(f\"Failed to upload to feed corresponding to ID {id} (HTTP {e.response.status_code})\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    except Exception as ex:\n",
    "        Stat.warning(f\"Failed to upload to feed corresponding to ID {id}: \" + str(ex), host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_batch_of_files():\n",
    "    lastUploaded = progress.get('lastUploaded', None)\n",
    "\n",
    "    files = get_newer_files(PurpleAirCommon.VOC_DATA_DIRECTORY, lastUploaded, num_subdir_levels=1)\n",
    "\n",
    "    # Only json files\n",
    "    files = list(filter(re.compile(r'\\.json$').search, files))\n",
    "\n",
    "    # A maximum of the first NUM_FILES_PER_BATCH files\n",
    "    files = files[0:NUM_FILES_PER_BATCH]\n",
    "\n",
    "    if len(files) > 0:\n",
    "        accumulate_reset()\n",
    "\n",
    "        Stat.up(f\"Processing {len(files)} data files\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME, valid_for_secs=RUN_INTERVAL_SECONDS * 1.5)\n",
    "        for file in files:\n",
    "            accumulate_json(PurpleAirCommon.VOC_DATA_DIRECTORY + '/' + file)\n",
    "\n",
    "        successful_upload_count = 0;\n",
    "        for id in sorted(accumulator.keys()):\n",
    "            if upload(id):\n",
    "                successful_upload_count += 1\n",
    "            # be nice to ESDR and sleep a bit\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        Stat.up(f\"Successfully uploaded {successful_upload_count} of {len(accumulator)} devices, with data from {len(files)} files [{files[0]} ... {files[-1]}]\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME, valid_for_secs=RUN_INTERVAL_SECONDS * 1.5)\n",
    "        progress['lastUploaded'] = files[-1]\n",
    "        return len(files)\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_purpleair_product()\n",
    "\n",
    "# Do this NUM_ITERATIONS_BETWEEN_RESTARTS times and then exit, relying on the cron job to start it up again. We do this\n",
    "# as a simple way to deal with refreshing the ESDR OAuth2 token, rather than adding code to catch the HTTP 401/403 error\n",
    "# upon upload, yada yada.\n",
    "for i in list(range(NUM_ITERATIONS_BETWEEN_RESTARTS)):\n",
    "    num_files_processed = process_one_batch_of_files()\n",
    "    if num_files_processed == 0:\n",
    "        Stat.info(f\"No files remaining to process, sleeping until next run period\", host=STAT_HOSTNAME, shortname=STAT_SHORTNAME)\n",
    "        sleep_until_next_period(RUN_INTERVAL_SECONDS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda Python3",
   "language": "python",
   "name": "anaconda3",
   "resource_dir": "/usr/local/share/jupyter/kernels/anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
