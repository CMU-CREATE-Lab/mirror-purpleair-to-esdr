{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#notebook-container { margin-left:-14px; width:calc(100% + 27px) !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wide display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>#notebook-container { margin-left:-14px; width:calc(100% + 27px) !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, datetime, fcntl, glob, json, math, os, re, subprocess, sys, time, urllib2, xml.dom.minidom, pytz\n",
    "from dateutil import rrule\n",
    "from dateutil import tz\n",
    "import dateutil.parser\n",
    "import numpy as np\n",
    "\n",
    "# To install dateutil on Ubuntu\n",
    "# sudo pip install python-dateutil\n",
    "\n",
    "def exec_ipynb(filename_or_url):\n",
    "    nb = (urllib2.urlopen(filename_or_url) if re.match(r'https?:', filename_or_url) else open(filename_or_url)).read()\n",
    "    jsonNb = json.loads(nb)\n",
    "    #check for the modified formatting of Jupyter Notebook v4\n",
    "    if(jsonNb['nbformat'] == 4):\n",
    "        exec '\\n'.join([''.join(cell['source']) for cell in jsonNb['cells'] if cell['cell_type'] == 'code']) in globals()\n",
    "    else:\n",
    "        exec '\\n'.join([''.join(cell['input']) for cell in jsonNb['worksheets'][0]['cells'] if cell['cell_type'] == 'code']) in globals()\n",
    "\n",
    "exec_ipynb('python-utils/esdr-library.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'created': u'2017-11-20T15:17:13.000Z',\n",
       " u'creatorUserId': 3,\n",
       " u'defaultChannelSpecs': {},\n",
       " u'description': u'PurpleAir',\n",
       " u'id': 69,\n",
       " u'modified': u'2017-11-20T15:17:13.000Z',\n",
       " u'name': u'PurpleAir',\n",
       " u'prettyName': u'PurpleAir',\n",
       " u'vendor': u'PurpleAir'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esdr = Esdr(None)\n",
    "product = esdr.get_product_by_name('PurpleAir')\n",
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 183 feeds\n",
      "First feed: {u'apiKeyReadOnly': u'2bd4d40a3059b5ef56a3f6a6b78386569da2c2580fcd5c42e497072119f7b79c', u'minTimeSecs': 1522247982.349, u'name': u'Monaca,PA PurpleAir', u'created': u'2018-03-28T14:51:40.000Z', u'isPublic': 1, u'userId': 3, u'modified': u'2018-12-23T20:27:30.000Z', u'longitude': -80.311057, u'channelBounds': {u'channels': {u'PM2_5': {u'maxTimeSecs': 1545595853.279, u'minTimeSecs': 1522247982.349, u'maxValue': 3810.59, u'minValue': 0}, u'stats_v': {u'maxTimeSecs': 1545595853.279, u'minTimeSecs': 1522247982.349, u'maxValue': 970.64, u'minValue': 0}, u'stats_pm': {u'maxTimeSecs': 1545595853.279, u'minTimeSecs': 1522247982.349, u'maxValue': 970.64, u'minValue': 0}, u'temp_f': {u'maxTimeSecs': 1545595853.279, u'minTimeSecs': 1522247982.349, u'maxValue': 105, u'minValue': 27}, u'humidity': {u'maxTimeSecs': 1545595853.279, u'minTimeSecs': 1522247982.349, u'maxValue': 84, u'minValue': 11}, u'pressure': {u'maxTimeSecs': 1545595853.279, u'minTimeSecs': 1522247982.349, u'maxValue': 993.69, u'minValue': 950.51}, u'stats_v6': {u'maxTimeSecs': 1545595853.279, u'minTimeSecs': 1522247982.349, u'maxValue': 20.72, u'minValue': 7.49}, u'stats_v4': {u'maxTimeSecs': 1545595853.279, u'minTimeSecs': 1522247982.349, u'maxValue': 61.8, u'minValue': 0.92}, u'stats_v5': {u'maxTimeSecs': 1545595853.279, u'minTimeSecs': 1522247982.349, u'maxValue': 31.71, u'minValue': 4.01}, u'stats_v2': {u'maxTimeSecs': 1545595853.279, u'minTimeSecs': 1522247982.349, u'maxValue': 137.6, u'minValue': 0.09}, u'stats_v3': {u'maxTimeSecs': 1545595853.279, u'minTimeSecs': 1522247982.349, u'maxValue': 108.58, u'minValue': 0.19}, u'stats_v1': {u'maxTimeSecs': 1545595853.279, u'minTimeSecs': 1522247982.349, u'maxValue': 263.4, u'minValue': 0.08}}, u'maxTimeSecs': 1545595853.279, u'minTimeSecs': 1522247982.349}, u'maxTimeSecs': 1545595853.279, u'channelSpecs': {}, u'deviceId': 17238, u'lastUpload': u'2018-12-23T20:27:30.000Z', u'latitude': 40.657411, u'exposure': u'outdoor', u'id': 17199, u'isMobile': 0, u'productId': 69}\n"
     ]
    }
   ],
   "source": [
    "feeds = []\n",
    "# Approx bounding box for Allegheny County\n",
    "region = 'latitude>40.192204,latitude<40.674084,longitude<-79.688618,longitude>-80.361022'\n",
    "offset = 0\n",
    "while True:\n",
    "    response = esdr.api('GET', '/api/v1/feeds', {'whereAnd' : 'productId=%d,%s' % (product['id'], region), 'offset': str(offset)})\n",
    "    data = response['data']\n",
    "    totalCount = data['totalCount']\n",
    "    nrecs = len(data['rows'])\n",
    "    feeds.extend(data['rows'])\n",
    "    limit = data['limit']\n",
    "    total_recvd = offset + nrecs\n",
    "    #print(offset, nrecs, limit, totalCount)\n",
    "    if total_recvd >= totalCount:\n",
    "        break\n",
    "    offset += nrecs\n",
    "\n",
    "print 'Retrieved %d feeds' % len(feeds)\n",
    "print 'First feed: %s' % feeds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_feed(feed, interval, from_epoch, to_epoch):\n",
    "    feed_id = feed['id']\n",
    "    export_url = 'https://esdr.cmucreatelab.org/api/v1/feeds/%d/channels/PM0.3/export?from=%d&to=%d&format=json' % (feed_id, from_epoch, to_epoch)\n",
    "    data = json.load(urllib2.urlopen(export_url))['data']\n",
    "    \n",
    "    \n",
    "#     print('Feed %d has %d samples' % (feed_id, len(data)))\n",
    "    if len(data) == 0:\n",
    "#         print('No samples, skipping')\n",
    "        return None\n",
    "\n",
    "    \n",
    "    dat = []\n",
    "    start_time = from_epoch\n",
    "    end_time = from_epoch + interval - 1\n",
    "\n",
    "    prevSample = 0\n",
    "    while((end_time+1) < to_epoch):\n",
    "        curbin = []\n",
    "        for sample in data:\n",
    "            if(sample[0] >= start_time and sample[0] <= end_time):\n",
    "                curbin.append(sample[1])\n",
    "        newSample = prevSample\n",
    "        if(len(curbin) > 0):    \n",
    "            newSample =  sum(curbin)/len(curbin)\n",
    "        if(newSample == 0):\n",
    "            newSample = prevSample\n",
    "     \n",
    "        start_time += interval\n",
    "        end_time += (interval-1)\n",
    "        \n",
    "        dat.append(newSample)\n",
    "        if(newSample != 0):\n",
    "            prevSample = newSample\n",
    "    \n",
    "    \n",
    "        \n",
    "    row = ['feed_%d' % feed_id, feed['latitude'], feed['longitude']] + list(dat)\n",
    " \n",
    "    return row\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'pop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c34c8a20ed53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msensor\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0msample_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m110\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1532822400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1532822400\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m86400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0msensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'pop'"
     ]
    }
   ],
   "source": [
    "sensor =  sample_feed(feeds[110], 1800, 1532822400, 1532822400+86400)\n",
    "sensor.pop(0)\n",
    "print sensor\n",
    "print len(np.array(sensor).astype(np.float32).tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_raw_binary(cur_date):\n",
    "    \n",
    "    #Gets datetime from string\n",
    "    date_datetime = datetime.datetime.strptime(cur_date, \"%Y-%m-%d\")\n",
    "    #Convert to datetime\n",
    "    epoch_time = (pytz.timezone('America/New_York').localize(date_datetime) - datetime.datetime(1970, 1, 1, tzinfo=pytz.utc)).total_seconds()\n",
    "    raw_data = []\n",
    "    bin_data = []\n",
    "    count = 0\n",
    "    for feed in feeds:\n",
    "\n",
    "        #Adds 24 hours to starting epoch_time\n",
    "        #Get each sensor feed sampled at 30 mins\n",
    "        sensor = sample_feed(feed, 300, epoch_time, epoch_time+86400)\n",
    "        \n",
    "        #Adds all non-NULL sensors to raw/bin data\n",
    "        if(sensor is not None and len(sensor) > 0):\n",
    "            count += 1\n",
    "            raw_data.append(sensor)\n",
    "            sensor.pop(0)\n",
    "            bin_data.append(sensor)\n",
    "    \n",
    "    #Convert to binary\n",
    "    raw_binary = np.array(bin_data).astype(np.float32).tobytes()\n",
    "\n",
    "    #Outputs binary file\n",
    "    path = \"aggregates/\"\n",
    "    bin_outfile = open(path + 'purpleair03_'  + cur_date + 'tmp.bin', 'w+')\n",
    "    bin_outfile.write(raw_binary)\n",
    "    bin_outfile.close()\n",
    "\n",
    "    #Outputs raw json file\n",
    "    path = \"aggregates/\"\n",
    "    with open(path + 'purpleair03_'  + cur_date + 'tmp.json', 'w+') as outfile:  \n",
    "        json.dump(raw_data, outfile)\n",
    "\n",
    "    os.rename(path + 'purpleair03_'  + cur_date + 'tmp.json', path + 'purpleair03_'  + cur_date + '.json')\n",
    "    os.rename(path + 'purpleair03_'  + cur_date + 'tmp.bin',  path + 'purpleair03_'  + cur_date + '.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-07\n",
      "2018-10-08\n",
      "2018-10-09\n",
      "2018-10-10\n",
      "2018-10-11\n",
      "2018-10-12\n",
      "2018-10-13\n",
      "2018-10-14\n",
      "2018-10-15\n",
      "2018-10-16\n",
      "2018-10-17\n",
      "2018-10-18\n",
      "2018-10-19\n",
      "2018-10-20\n",
      "2018-10-21\n",
      "2018-10-22\n",
      "2018-10-23\n",
      "2018-10-24\n",
      "2018-10-25\n",
      "2018-10-26\n",
      "2018-10-27\n",
      "2018-10-28\n",
      "2018-10-29\n",
      "2018-10-30\n",
      "2018-10-31\n",
      "2018-11-01\n",
      "2018-11-02\n",
      "2018-11-03\n",
      "2018-11-04\n",
      "2018-11-05\n",
      "2018-11-06\n",
      "2018-11-07\n",
      "2018-11-08\n",
      "2018-11-09\n",
      "2018-11-10\n",
      "2018-11-11\n",
      "2018-11-12\n",
      "2018-11-13\n",
      "2018-11-14\n",
      "2018-11-15\n",
      "2018-11-16\n",
      "2018-11-17\n",
      "2018-11-18\n",
      "2018-11-19\n",
      "2018-11-20\n",
      "2018-11-21\n",
      "2018-11-22\n",
      "2018-11-23\n",
      "2018-11-24\n",
      "2018-11-25\n",
      "2018-11-26\n",
      "2018-11-27\n",
      "2018-11-28\n",
      "2018-11-29\n",
      "2018-11-30\n",
      "2018-12-01\n",
      "2018-12-02\n",
      "2018-12-03\n",
      "2018-12-04\n",
      "2018-12-05\n",
      "2018-12-06\n",
      "2018-12-07\n",
      "2018-12-08\n",
      "2018-12-09\n",
      "2018-12-10\n",
      "2018-12-11\n",
      "2018-12-12\n",
      "2018-12-13\n",
      "2018-12-14\n",
      "2018-12-15\n",
      "2018-12-16\n",
      "2018-12-17\n",
      "2018-12-18\n",
      "2018-12-19\n",
      "2018-12-20\n",
      "2018-12-21\n",
      "2018-12-22\n",
      "2018-12-23\n",
      "2018-12-24\n",
      "2018-12-25\n",
      "2018-12-26\n",
      "2018-12-27\n",
      "2018-12-28\n",
      "2018-12-29\n",
      "2018-12-30\n",
      "2018-12-31\n",
      "2019-01-01\n",
      "2019-01-02\n",
      "2019-01-03\n",
      "2019-01-04\n",
      "2019-01-05\n",
      "2019-01-06\n",
      "2019-01-07\n",
      "2019-01-08\n",
      "2019-01-09\n",
      "2019-01-10\n",
      "2019-01-11\n",
      "2019-01-12\n",
      "2019-01-13\n",
      "2019-01-14\n",
      "2019-01-15\n",
      "2019-01-16\n",
      "2019-01-17\n",
      "2019-01-18\n",
      "2019-01-19\n",
      "2019-01-20\n",
      "2019-01-21\n",
      "2019-01-22\n",
      "2019-01-23\n",
      "2019-01-24\n",
      "2019-01-25\n",
      "2019-01-26\n",
      "2019-01-27\n",
      "2019-01-28\n",
      "2019-01-29\n"
     ]
    }
   ],
   "source": [
    "#Get current time\n",
    "curDate = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "curDate = '2018-10-07'\n",
    "while(curDate != '2019-01-30'):\n",
    "    print(curDate)\n",
    "    output_raw_binary(curDate)\n",
    "    curDate = (datetime.datetime.strptime(curDate, '%Y-%m-%d')+datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
